<!DOCTYPE html><html lang="zh-CN" theme-mode="dark"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>人工智能 - 联邦学习(安全性) - 自用(ProjectDoing) | Tisfy的LeetCode题解等博客</title><link rel="canonical" href="https://blog.letmefly.xyz/2024/01/06/Other-AI-FL-FederatedLearning-ProjectWritingIn1month/"><link rel="icon" type="image/x-icon" href="https://web.letmefly.xyz/favicon.ico"><link rel="preload" as="font" crossorigin="anonymous" href="/theme/arknights/font/Bender.ttf"><link rel="preload" as="font" crossorigin="anonymous" href="/theme/arknights/font/BenderLight.ttf"><link rel="preload" as="font" crossorigin="anonymous" href="/theme/arknights/font/JetBrainsMono-Regular.woff2"><link rel="stylesheet" href="/theme/arknights/css/arknights.css"><style>@font-face {
  font-family: Bender;
  src: local('Bender'), url("/theme/arknights/font/Bender.ttf"), url("/theme/arknights/font/Bender.otf");
}
@font-face {
  font-family: BenderLight;
  src: local('BenderLight'), url("/theme/arknights/font/BenderLight.ttf");
}
@font-face {
  font-family: 'JetBrains Mono';
  src: local('JetBrains Mono'), url('/theme/arknights/font/JetBrainsMono-Regular.woff2') format('woff2');
}
</style><script>var config = {"root":"/theme/arknights/","search":{"preload":false,"activeHolder":"Enter here","blurHolder":"Search","noResult":"Data \"$0\" not found"},"code":{"codeInfo":"$0 - $1 lines","copy":"copy"}}</script><link type="text/css" rel="stylesheet" href="/theme/arknights/lib/encrypt/hbe.style.css"><link type="text/css" rel="stylesheet" href="//unpkg.com/lightgallery@2.7.1/css/lightgallery.css"><link type="text/css" rel="stylesheet" href="//unpkg.com/lightgallery@2.7.1/css/lg-zoom.css"><link type="text/css" rel="stylesheet" href="//unpkg.com/lightgallery@2.7.1/css/lg-thumbnail.css"><link type="text/css" rel="stylesheet" href="/theme/arknights/lib/fontawesome/css/all.min.css"><script>if (window.localStorage.getItem('theme-mode') === 'light')
 document.documentElement.setAttribute('theme-mode', 'light')
if (window.localStorage.getItem('theme-mode') === 'dark')
 document.documentElement.setAttribute('theme-mode', 'dark')</script><style>:root {
 --dark-background: url('https://ak.hypergryph.com/assets/index/images/ak/pc/bk.jpg');
 --light-background: url('/theme/arknights/img/bk.jpg');
 --theme-encrypt-confirm: 'confirm'
}</style><script defer src="/theme/arknights/js/arknights.js"></script><script defer type="module">window.MathJax = { tex: { inlineMath: [['$', '$'], ['\\(', '\\)']], }, chtml: { scale: 0.8 }};
</script><script defer src="https://letmefly.xyz/Links/JS/MathJax/tex-mml-chtml.js"></script><script defer src="/theme/arknights/js/search.js"></script><script defer type="module">import mermaid from '//unpkg.com/mermaid@10.5.0/dist/mermaid.esm.mjs';
window.mermaid = mermaid;
code.paintMermaid();
</script><script defer src="https://letmefly.xyz/Links/Common.js"></script><script async src="//unpkg.com/lightgallery@2.7.1/lightgallery.min.js"></script><script async src="//unpkg.com/lightgallery@2.7.1/plugins/zoom/lg-zoom.min.js"></script><script async src="//unpkg.com/lightgallery@2.7.1/plugins/thumbnail/lg-thumbnail.min.js"></script><script async src="/theme/arknights/lib/encrypt/hbe.js"></script><script async src="/theme/arknights/js/pjax.js"></script><script class="pjax-js">reset= () => {document.querySelector('.lg-container')?.remove()
lightGallery(document.getElementById('post-bg'), {
  plugins: [lgZoom,lgThumbnail],
  selector: '.item-img'})}</script><script>window.addEventListener("load",() => {pjax = new Pjax({
 cacheBust: false,
 selectors: ['title','article','#aside-block','.pjax-js','data-pjax','.busuanzi'],
 switches: {'article': Pjax.switches.sideBySide},
 switchesOptions: {
   'article': {
     classNames: {
       remove: "pjax-out",
       add: "pjax-in"
     }
   }
 }
});
document.addEventListener("pjax:complete", reset);reset()})</script><meta name="generator" content="Hexo 8.1.1"></head><body><div class="loading" style="opacity: 0;"><div class="loadingBar left"></div><div class="loadingBar right"></div></div><main><header class="closed"><div class="navBtn"><i class="navBtnIcon"><span class="navBtnIconBar"></span><span class="navBtnIconBar"></span><span class="navBtnIconBar"></span></i></div><nav><div class="navItem" id="search-header"><span class="navItemTitle"><input autocomplete="off" autocorrect="off" autocapitalize="none" placeholder="Search" spellcheck="false" maxlength="50" type="text" id="search-input"></span></div><div class="navItem" id="search-holder"></div><div class="search-popup" tabindex="0"><div id="search-result"></div></div><ol class="navContent"><li class="navItem"><a class="navBlock" href="/theme/arknights/"><span class="navItemTitle">Home</span></a></li><li class="navItem" matchdata="categories,tags"><a class="navBlock" href="/theme/arknights/archives/"><span class="navItemTitle">Archives</span></a></li></ol></nav></header><article><div id="post-bg"><div id="post-title"><h1>人工智能 - 联邦学习(安全性) - 自用(ProjectDoing)</h1><div id="post-info"><span>First Post: <div class="control"><time datetime="2024-01-06T04:32:45.000Z" id="date"> 2024-01-06</time></div></span></div></div><hr><div id="post-content"><h1 id="FL"><a href="#FL" class="headerlink" title="FL"></a>FL</h1><h2 id="一点名词解释"><a href="#一点名词解释" class="headerlink" title="一点名词解释"></a>一点名词解释</h2><p>后门攻击成功的指标：</p>
<ul>
<li>干净数据准确率（Clean Data Accuracy, CDA）：不带trigger的干净样本被成功预测的概率</li>
<li>攻击成功率（Attack Success Rate, ASR）：带trigger的样本被预测为攻击者指定类的概率</li>
</ul>
<h2 id="2024-1-4-15-00-2024-1-6-14-30"><a href="#2024-1-4-15-00-2024-1-6-14-30" class="headerlink" title="2024.1.4(15:00)-2024.1.6(14:30)"></a>2024.1.4(15:00)-2024.1.6(14:30)</h2><p><strong>任务</strong></p>
<p>Learn FL，找数据集</p>
<p><strong>数据集</strong></p>
<p>其中<a target="_blank" rel="noopener" href="https://leaf.cmu.edu/">LEAF</a>提供了几个联邦学习的基准数据集。</p>
<p>准备选择下面列表中的前3个。</p>
<ul>
<li>MNIST: 手写数字识别（<a target="_blank" rel="noopener" href="https://yann.lecun.com/exdb/mnist/">官网(访问需要密码)</a>、<a target="_blank" rel="noopener" href="https://web.archive.org/web/20231229081350/http://yann.lecun.com/exdb/mnist/">官网的Web Archive</a>、<a target="_blank" rel="noopener" href="https://www.kaggle.com/datasets/hojjatk/mnist-dataset">Kaggle数据集</a>）</li>
<li>CIFAR-10：airplane automobile bird cat deer dog frog horse ship truck（<a target="_blank" rel="noopener" href="https://www.cs.toronto.edu/~kriz/cifar.html">官网</a>、<a target="_blank" rel="noopener" href="https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz">数据集</a>）</li>
<li>FEMINIST: 识别英文字母和数字（<a target="_blank" rel="noopener" href="https://github.com/TalwalkarLab/leaf">官方数据预处理与划分代码</a>，<a target="_blank" rel="noopener" href="https://s3.amazonaws.com/nist-srd/SD19/by_class.zip">下载地址1 by_class</a>、<a target="_blank" rel="noopener" href="https://s3.amazonaws.com/nist-srd/SD19/by_write.zip">下载地址2 by_write</a>）</li>
<li>FMINIST(FashionMNIST): 物品识别</li>
</ul>
<h2 id="2024-1-6-16-10-2024-1-9-10-00"><a href="#2024-1-6-16-10-2024-1-9-10-00" class="headerlink" title="2024.1.6(16:10)-2024.1.9(10:00)"></a>2024.1.6(16:10)-2024.1.9(10:00)</h2><p><strong>任务</strong></p>
<ul>
<li><input checked="" disabled="" type="checkbox"> 数据集的更换</li>
<li><input disabled="" type="checkbox"> 搞懂FL、ViT（理解 + Code）</li>
<li><input checked="" disabled="" type="checkbox"> 过程中遇到有帮助的图留意下</li>
<li><input checked="" disabled="" type="checkbox"> 完成后预定1.8日晚或1.9日早的会议</li>
</ul>
<p><strong>数据集</strong></p>
<p>数据集最终决定使用这三个：</p>
<ul>
<li>MNIST: 手写数字识别（<a target="_blank" rel="noopener" href="https://yann.lecun.com/exdb/mnist/">官网(访问需要密码)</a>、<a target="_blank" rel="noopener" href="https://web.archive.org/web/20231229081350/http://yann.lecun.com/exdb/mnist/">官网的Web Archive</a>、<a target="_blank" rel="noopener" href="https://www.kaggle.com/datasets/hojjatk/mnist-dataset">Kaggle数据集</a>）</li>
<li>CIFAR-10: airplane automobile bird cat deer dog frog horse ship truck（<a target="_blank" rel="noopener" href="https://www.cs.toronto.edu/~kriz/cifar.html">官网</a>、<a target="_blank" rel="noopener" href="https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz">数据集</a>）</li>
<li>OrganAMNIST: 其实是属于<a target="_blank" rel="noopener" href="https://www.nature.com/articles/s41597-022-01721-8">MedMNIST</a>（<a target="_blank" rel="noopener" href="https://zenodo.org/records/6496656">MedMNIST数据集</a>、<a target="_blank" rel="noopener" href="https://zenodo.org/records/6496656/files/organamnist.npz?download=1">OrganAMNIST</a>）</li>
</ul>
<h2 id="2024-1-9-19-00-近几天-待定"><a href="#2024-1-9-19-00-近几天-待定" class="headerlink" title="2024.1.9(19:00)-近几天(待定)"></a>2024.1.9(19:00)-近几天(待定)</h2><p><strong>任务</strong></p>
<ul>
<li><input disabled="" type="checkbox"> 看模型结构(2024.1.10)</li>
<li><input disabled="" type="checkbox"> ViT敏感层确定</li>
<li><input disabled="" type="checkbox"> 画出实验图</li>
<li><input disabled="" type="checkbox"> 写理论部分</li>
<li><input disabled="" type="checkbox"> 设计实验并执行</li>
</ul>
<p>其他（小杂）：</p>
<ul>
<li>攻击找两三个backdoor；防御 现有的 替换个</li>
<li>安全性（识别、结果、…）</li>
<li>名字：mask（安全掩码）</li>
<li>图：选层 放大</li>
<li><ol>
<li>ViT选层、2. 放大、3. cos计算（信用）</li>
</ol>
</li>
</ul>
<h2 id="2024-5-14-2024-5-19"><a href="#2024-5-14-2024-5-19" class="headerlink" title="2024.5.14-2024.5.19"></a>2024.5.14-2024.5.19</h2><p>暂时停止在<a target="_blank" rel="noopener" href="https://github.com/LetMeFly666/FLDefinder/commit/c830b55950ba84a8dd657bbd4ecfa247c6c3e8a5">原有</a>基础上继续更改，<a target="_blank" rel="noopener" href="https://github.com/LetMeFly666/FLDefinder/commit/fd9f0fa1c57a6f9194e49d14c3fd0ac00779f3a4">开始</a>寻找现有的联邦学习ViT Backdoor的代码并在此基础上进行更改。</p>
<p>小目标：跑通某个现有代码，达到应有的准确率。</p>
<h2 id="2024-6-3-2024-6-27"><a href="#2024-6-3-2024-6-27" class="headerlink" title="2024.6.3-2024.6.27"></a>2024.6.3-2024.6.27</h2><p>全力写本子。</p>
<h2 id="2024-7-1-2024-7-10"><a href="#2024-7-1-2024-7-10" class="headerlink" title="2024.7.1-2024.7.10"></a>2024.7.1-2024.7.10</h2><ul>
<li>7.1-7.2(上午)：再熟悉一下FL(攻防)基本知识</li>
<li>7.2(下午)-7.3：定下最终思路</li>
<li>7.4-7.8：代码实现&#x2F;实验结果跑完</li>
<li>7.9-7.10：初稿写完</li>
</ul>
<h3 id="思路一"><a href="#思路一" class="headerlink" title="思路一"></a>思路一</h3><p>经典特征层提取。</p>
<p>根据<a target="_blank" rel="noopener" href="https://dl.acm.org/doi/abs/10.1145/3564625.3564658">Better Together</a>，此类实验主要有三个指标：</p>
<ol>
<li>鲁棒性</li>
<li>保真度</li>
<li>效率</li>
</ol>
<p>特征层提取的话，对于鲁棒性，<strong>未完待续</strong></p>
<h2 id="2024-7-1-2024-7-15"><a href="#2024-7-1-2024-7-15" class="headerlink" title="2024.7.1-2024.7.15"></a>2024.7.1-2024.7.15</h2><p>IEEE UIC2024的<a target="_blank" rel="noopener" href="https://github.com/LetMeFly666/ViT-MGI">ViT-MGI</a>初稿已定，几乎不会怎么改了。</p>
<h2 id="2024-7-18-2024-7-22-周一"><a href="#2024-7-18-2024-7-22-周一" class="headerlink" title="2024.7.18 - 2024.7.22(周一)"></a>2024.7.18 - 2024.7.22(周一)</h2><p>扩刊idea。主要有以下两个方面：</p>
<ol>
<li>深入一下ViT，有无能更加针对ViT的工作？</li>
<li>读一些最新攻防，高级攻击如何防？</li>
</ol>
<p>以上以2为主。</p>
<p>周一找赞哥讨论。</p>
<h2 id="2024-7-23-2024-7-29-周一"><a href="#2024-7-23-2024-7-29-周一" class="headerlink" title="2024.7.23 - 2024.7.29(周一)"></a><del>2024.7.23 - 2024.7.29(周一)</del></h2><p>更具体一点的idea。</p>
<p>周一找赞哥讨论。</p>
<h2 id="2024-7-22-下午-2024-7-23-下午-晚上"><a href="#2024-7-22-下午-2024-7-23-下午-晚上" class="headerlink" title="2024.7.22(下午) - 2024.7.23(下午&#x2F;晚上)"></a>2024.7.22(下午) - 2024.7.23(下午&#x2F;晚上)</h2><ol>
<li>了解一下北邮超算平台，使用赞哥工号开通一个</li>
<li>了解大模型，什么样才算大模型，大模型一般怎么训(冻结调参?)，如何与视觉挂钩(甚至是ViT)，能否联邦学习</li>
<li>确定两个视觉相关大模型(能训得出来那种比较小的大模型)，确定两个数据集，确定具体怎么训</li>
</ol>
<p><strong>参数量：</strong> 没有明确定义，通常具有数十亿规模参数甚至更多。当然也有较小的几千万参数的“大模型”。</p>
<p><strong>能否联邦学习：</strong> 能，ViT就FL了。</p>
<p><strong>大模型选择：</strong></p>
<ol>
<li>ViT也能算得上大模型，尤其是<code>ViT-Large</code>和<code>ViT-Huge</code>。<ul>
<li><code>ViT-Base (ViT-B/16)</code>：8600万参数</li>
<li><code>ViT-Large (ViT-L/16)</code>：3.07亿参数</li>
<li><code>ViT-Huge (ViT-H/14)</code>：6.32亿参数</li>
</ul>
</li>
<li>Swin Transformer：是一种分层视觉Transformer模型，在图像分类、目标检测和图像分割等任务上表现出色。<ul>
<li><code>Swin-Tiny</code>：2900万参数</li>
<li><code>Swin-Small</code>：5000万参数</li>
<li><code>Swin-Base</code>：8800万参数</li>
<li><code>Swin-Large</code>：1.97亿参数</li>
</ul>
</li>
<li>ResNet-152：是一种深层卷积神经网络，在多个视觉任务中表现优异。<ul>
<li>6000万参数</li>
</ul>
</li>
</ol>
<table>
<thead>
<tr>
<th>特点</th>
<th>Vision Transformer (ViT)</th>
<th>Swin Transformer</th>
</tr>
</thead>
<tbody><tr>
<td>架构</td>
<td>直接使用Transformer架构处理patch</td>
<td>分层设计，使用窗口注意力和移动窗口机制</td>
</tr>
<tr>
<td>优点</td>
<td>强大表示能力，简化设计</td>
<td>计算效率高，适合多任务和高分辨率图像</td>
</tr>
<tr>
<td>缺点</td>
<td>计算资源要求高，处理高分辨率图像复杂</td>
<td>结构复杂，需要精细设计和调优</td>
</tr>
<tr>
<td>图像分类性能</td>
<td>大规模数据上表现优异</td>
<td>各种数据规模上表现良好</td>
</tr>
<tr>
<td>目标检测和图像分割</td>
<td>可能表现不如专门设计的模型</td>
<td>表现出色</td>
</tr>
<tr>
<td>计算复杂度</td>
<td>高，尤其是高分辨率图像</td>
<td>较低，适合高分辨率图像处理</td>
</tr>
</tbody></table>
<p><strong>数据集选择：</strong></p>
<table>
<thead>
<tr>
<th>数据集名称</th>
<th>数据量</th>
<th>标签数</th>
<th>特点</th>
<th>主要应用模型</th>
<th>数据集类型</th>
</tr>
</thead>
<tbody><tr>
<td>ImageNet-1k</td>
<td>120万</td>
<td>1,000</td>
<td>大规模图像分类基准，常用于模型预训练和评估</td>
<td>ViT, Swin Transformer, DeiT</td>
<td>自然图像分类</td>
</tr>
<tr>
<td>ImageNet-21k</td>
<td>1400万</td>
<td>21,000</td>
<td>包含更多类别，适合大规模预训练</td>
<td>ViT, Swin Transformer</td>
<td>自然图像分类</td>
</tr>
<tr>
<td>CIFAR-10</td>
<td>60,000</td>
<td>10</td>
<td>小规模数据集，常用于快速验证模型性能</td>
<td>ViT, DeiT</td>
<td>小型自然图像分类</td>
</tr>
<tr>
<td>CIFAR-100</td>
<td>60,000</td>
<td>100</td>
<td>与CIFAR-10类似，但分类更细致</td>
<td>ViT, DeiT</td>
<td>小型自然图像分类</td>
</tr>
<tr>
<td>Tiny ImageNet</td>
<td>100,000</td>
<td>200</td>
<td>中等规模数据集，适用于模型性能验证</td>
<td>ViT, DeiT</td>
<td>自然图像分类</td>
</tr>
<tr>
<td>COCO</td>
<td>330,000</td>
<td>80</td>
<td>多任务数据集，广泛用于目标检测和图像分割</td>
<td>Swin Transformer, SegFormer</td>
<td>目标检测、图像分割、物体识别</td>
</tr>
<tr>
<td>ADE20K</td>
<td>25,000</td>
<td>150</td>
<td>用于语义分割任务的标准数据集</td>
<td>Swin Transformer, SegFormer</td>
<td>语义分割</td>
</tr>
<tr>
<td>Cityscapes</td>
<td>5,000</td>
<td>30</td>
<td>专用于城市街景图像分割，评估模型在真实场景的表现</td>
<td>Swin Transformer, SegFormer</td>
<td>城市街景图像分割</td>
</tr>
<tr>
<td>Pascal VOC</td>
<td>9,000</td>
<td>20</td>
<td>经典的目标检测和分类数据集，应用广泛</td>
<td>Swin Transformer, SegFormer</td>
<td>目标检测和分类</td>
</tr>
</tbody></table>
<h2 id="2024-7-23-晚上-2024-7-24-暂定晚上"><a href="#2024-7-23-晚上-2024-7-24-暂定晚上" class="headerlink" title="2024.7.23(晚上) - 2024.7.24(暂定晚上)"></a>2024.7.23(晚上) - 2024.7.24(暂定晚上)</h2><p>前面的调研不中。</p>
<ul>
<li>大模型的具体步骤</li>
<li>视觉大模型的具体步骤</li>
</ul>
<p>可以找找近两年论文里图像分类的大模型都用的啥，具体是怎么微调的。</p>
<h1 id="End"><a href="#End" class="headerlink" title="End"></a>End</h1><blockquote>
<p>原创不易，转载请附上<a href="https://blog.letmefly.xyz/2024/01/06/Other-AI-FL-FederatedLearning-ProjectWritingIn1month/">原文链接</a>哦~<br><a href="https://blog.letmefly.xyz/2024/01/06/Other-AI-FL-FederatedLearning-ProjectWritingIn1month/">https://blog.letmefly.xyz/2024/01/06/Other-AI-FL-FederatedLearning-ProjectWritingIn1month/</a></p>
</blockquote>
<div id="paginator"></div></div><div id="post-footer"><div id="pages"><div class="footer-link" style="width: 50%;text-align:right;border-right:1px #fe2 solid"><a href="/theme/arknights/2024/01/07/LeetCode%200383.%E8%B5%8E%E9%87%91%E4%BF%A1/">← Next 383.赎金信</a></div><div class="footer-link" style="width: 50%;right:1px;border-left:1px #fe2 solid"><a href="/theme/arknights/2024/01/06/LeetCode%202807.%E5%9C%A8%E9%93%BE%E8%A1%A8%E4%B8%AD%E6%8F%92%E5%85%A5%E6%9C%80%E5%A4%A7%E5%85%AC%E7%BA%A6%E6%95%B0/">2807.在链表中插入最大公约数 Prev →</a></div></div></div></div><div class="bottom-btn"><div><a class="i-top" id="to-top" onClick="scrolls.scrolltop();" title="To Top" style="opacity: 0; display: none;">∧ </a><a class="i-index" id="to-index" href="#toc-div" title="To Catalog">≡</a><a class="i-color" id="color-mode" onClick="colorMode.change()" title="Change Theme"></a></div></div></article><aside><div id="about"><a href="/theme/arknights/" id="logo"><img src="https://ak.hypergryph.com/assets/index/images/ak/pc/faction/1.png" alt="Logo"></a><h1 id="Dr"><a href="/">&lt;a href=&quot;https://letmefly.xyz&quot;&gt;Tisfy&lt;/a&gt;</a></h1><div id="description"><p>LeetCode 题解、解题技巧 力扣题解 技术博客</p></div><div id="social-links"><a class="social" target="_blank" rel="noopener" href="https://github.com/LetMeFly666"><i class="fab fa-github" alt="GitHub"></i></a><a class="social" target="_blank" rel="noopener" href="https://space.bilibili.com/440206990"><i class="fa-brands fa-bilibili" alt="BiliBili"></i></a></div></div><div id="aside-block"><div id="toc-div"><h1>Catalog</h1><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#FL"><span class="toc-number">1.</span> <span class="toc-text">FL</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E7%82%B9%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A"><span class="toc-number">1.1.</span> <span class="toc-text">一点名词解释</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2024-1-4-15-00-2024-1-6-14-30"><span class="toc-number">1.2.</span> <span class="toc-text">2024.1.4(15:00)-2024.1.6(14:30)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2024-1-6-16-10-2024-1-9-10-00"><span class="toc-number">1.3.</span> <span class="toc-text">2024.1.6(16:10)-2024.1.9(10:00)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2024-1-9-19-00-%E8%BF%91%E5%87%A0%E5%A4%A9-%E5%BE%85%E5%AE%9A"><span class="toc-number">1.4.</span> <span class="toc-text">2024.1.9(19:00)-近几天(待定)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2024-5-14-2024-5-19"><span class="toc-number">1.5.</span> <span class="toc-text">2024.5.14-2024.5.19</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2024-6-3-2024-6-27"><span class="toc-number">1.6.</span> <span class="toc-text">2024.6.3-2024.6.27</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2024-7-1-2024-7-10"><span class="toc-number">1.7.</span> <span class="toc-text">2024.7.1-2024.7.10</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%9D%E8%B7%AF%E4%B8%80"><span class="toc-number">1.7.1.</span> <span class="toc-text">思路一</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2024-7-1-2024-7-15"><span class="toc-number">1.8.</span> <span class="toc-text">2024.7.1-2024.7.15</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2024-7-18-2024-7-22-%E5%91%A8%E4%B8%80"><span class="toc-number">1.9.</span> <span class="toc-text">2024.7.18 - 2024.7.22(周一)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2024-7-23-2024-7-29-%E5%91%A8%E4%B8%80"><span class="toc-number">1.10.</span> <span class="toc-text">2024.7.23 - 2024.7.29(周一)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2024-7-22-%E4%B8%8B%E5%8D%88-2024-7-23-%E4%B8%8B%E5%8D%88-%E6%99%9A%E4%B8%8A"><span class="toc-number">1.11.</span> <span class="toc-text">2024.7.22(下午) - 2024.7.23(下午&#x2F;晚上)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2024-7-23-%E6%99%9A%E4%B8%8A-2024-7-24-%E6%9A%82%E5%AE%9A%E6%99%9A%E4%B8%8A"><span class="toc-number">1.12.</span> <span class="toc-text">2024.7.23(晚上) - 2024.7.24(暂定晚上)</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#End"><span class="toc-number">2.</span> <span class="toc-text">End</span></a></li></ol></div></div><footer><nobr><span class="icp-title">ICP</span><a class="icp-content" target="_blank" rel="noopener" href="https://beian.miit.gov.cn/">京ICP备2021029766号-1</a></nobr><br><nobr><span class="icp-title">copyright</span><a class="icp-content" target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">CC BY-NC-SA 4.0</a></nobr><br><nobr><a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a><span>'s </span><a target="_blank" rel="noopener" href="https://github.com/Yue-plus/hexo-theme-arknights">Arknights</a></nobr><wbr><nobr>ALL atricles by<a target="_blank" rel="noopener" href="https://letmefly.xyz/">Tisfy</a></nobr></footer></aside></main><canvas id="canvas-dust"></canvas></body></html>