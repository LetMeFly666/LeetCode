<!--
 * @Author: LetMeFly
 * @Date: 2025-05-30 10:30:42
 * @LastEditors: LetMeFly.xyz
 * @LastEditTime: 2025-06-06 21:19:54
-->
本月的前半部分进行了视觉大模型联邦学习过程中攻击识别检测成功率和效率比较冲突的问题的完善，后半部分开始了毕业设计第二个创新点——LVLM隐蔽后门攻击防御问题的研究。

在针对视觉大模型联邦学习过程中攻击识别检测成功率的问题上，本月在上个月思路的基础上进行了实验验证。首先搭建了一套简单的攻击防御系统用来验证较为经典的攻击和较为隐蔽的攻击的可成功性。在特征层的确定上，分别使用不同层作为全部参数进行相同的检测算法，挑选每次识别结果最好的层作为特征层。识别效率的检测上，对比传统的PCA、隔离森林及同样是为了降低数据维度的池化，提取特征层的方法在识别效率和准确率上都更有优势。

在针对LVLM隐蔽后门攻击防御的问题上，本月进行了相关的调研，调研了一些联邦学习攻防相关的算法，借鉴已有思路，试图寻找一个攻击者的共性。



---


几乎每出现一种新的防御方式，都会随之出现一种或多种针对它的新的攻击方式；每出现一种新的攻击方式，都会出现一种新的针对它的防御方式。有的攻击方式是针对梯度的，有的是针对余弦相似度的，有的甚至能够拓展到频域上进行攻防，给人一种道高一丈魔高一尺的表现。

但是，不论攻击设计地有多么隐蔽，其最终一定是要引导模型走向一个非预期的位置。因此，是否能够设计一种方式，计算每个客户的上传梯度想要将模型引导至的“目标位置”，从而直接根据客户端的最终目的进行恶意攻击的识别和检测？

如果能够设计出来，那么这种方法似乎将会成为一种较通用的联邦学习恶意攻击检测方法了。

————


下个月

这个客户端这次正常下次不正常怎么办

解决办法： 综合多轮历史