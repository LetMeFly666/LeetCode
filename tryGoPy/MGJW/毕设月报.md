<!--
 * @Author: LetMeFly
 * @Date: 2025-03-20 09:23:23
 * @LastEditors: LetMeFly.xyz
 * @LastEditTime: 2025-03-20 17:04:16
-->
在上个月的研究中，对于问题的解决方案似乎已经初见端倪。上月已经有了将算力“聚焦”在高效的参数上似乎就能减少计算量的初步想法，同时有了对于若没有“无效”参数的干扰，检测准确率似乎也能有所提升的猜测。
本月的研究内容中，主要针对上述猜想进行了调研，阅读了较多文献，分析了现有的联邦学习恶意攻击检测算法的优缺点，以及现有的联邦学习攻击防御算法中是如何对计算量进行权衡操作的。结果发现，为了应对联邦学习中计算量过多的问题，大多检测算法都使用了池化等方式来降低数据量。本月尝试将池化技术应用到ViT的联邦学习攻防实验中，结果发现效果有些不尽人意，虽然通过池化的方式减少了数据量，提高了恶意检测的识别效率，但是检测准确率也出现了明显的下降。分析其原因发现可能是由于池化这种降维方式会导致攻击和防御者的一些特征较为类似。丢失掉一些攻击者的特征，从而降低识别准确率。
由于无脑池化的方式可能会盲目选择参数去消减，所以如果能够选择消减区别不大的低效参数，理论上就可能能够在减少运算量的同时减小恶意非恶意用户之间区别较小的参数并提高识别准确率了。
因此问题就转换为了如何识别ViT模型在特定场景下哪些参数较为高效活跃哪些参数变化较为不明显来选择性地在恶意检测的过程中保留高效参数。
由于ViT由不同的层组成，所以本月进行了每一层的参数变化分析。针对特定的任务场景，打印并分析了每一层参数的变化情况。结果发现，其中一些层对于特定的任务十分敏感，而有的层在处理特定的任务时参数几乎不会发生变化。
对于此场景，使用了不同的数据集，发现这些层都有类似的活跃性和不活跃性的行为。





在上个月的研究中，对于问题的解决方案似乎已经初见端倪。上月已经有了将算力“聚焦”在高效的参数上似乎就能减少计算量的初步想法，同时有了对于若没有“无效”参数的干扰，检测准确率似乎也能有所提升的猜测。
本月的研究内容中，分析了现有的联邦学习恶意攻击检测算法的优缺点，以及现有的联邦学习攻击防御算法中是如何对计算量进行权衡操作的。一些算法使用池化等方式来降低数据量。本月尝试将池化技术应用到ViT中，结果发现虽然通过池化的方式减少了数据量，提高了恶意检测的识别效率，但是检测准确率也出现了明显的下降。分析其原因发现池化这种降维方式会导致攻击防御者的一些特征较为类似，丢失掉了一些攻击者的特征从而降低识别准确率。
因此问题就转换为了如何识别ViT模型在特定场景下哪些参数较为高效活跃哪些参数变化较为不明显来选择性地在恶意检测的过程中保留高效参数。
本月进行了ViT每一层的参数变化分析。针对特定的任务场景，打印并分析了每一层参数的变化情况并发现其中一些层对于特定的任务十分敏感，而有的层在处理特定的任务时参数几乎不会发生变化。对于此场景，使用了不同的数据集，发现这些层都有类似的活跃性和不活跃性的行为。




由于无脑池化的方式可能会盲目选择参数去消减，所以如果能够选择消减区别不大的低效参数，理论上就可能能够在减少运算量的同时减小恶意非恶意用户之间区别较小的参数并提高识别准确率了。
本月已经进行了不同层参数变化情况的分析，发现了一种可行的保留高效参数丢弃低效参数的方案，但是仍然存在一些很客观的问题：
1. 本方法过于依赖人工经验，针对特定的任务场景需要特定的分析来确定保留哪些层
2. 恶意攻击者若得知中央聚合服务器所保留的层，可能会特此针对这一检测算法，仅仅篡改中央聚合服务器所不关注的层或者很少更改聚合服务器关注的层的参数，从而绕开检测算法。